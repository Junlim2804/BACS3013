{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Demo : [IRIS](https://archive.ics.uci.edu/ml/datasets/Iris) dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "import pandas as pd\n",
    "\n",
    "X_iris = iris.drop('species', axis=1)\n",
    "y_iris = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
    "model = GaussianNB()                       # 2. instantiate model\n",
    "model.fit(Xtrain, ytrain)                  # 3. fit model to data\n",
    "y_model = model.predict(Xtest)             # 4. predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB: (shhh.... I am **naive** but I am **smart**!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, KNN Classifier\n",
    "\n",
    "more [info](https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn: hahaha, I am smarter than you, GaussianNB!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of KNN\n",
    "\n",
    "**Pros**\n",
    "\n",
    "One of the most attractive features of the K-nearest neighbor algorithm is that is **simple to understand and easy to implement**. \n",
    "\n",
    "**Cons**\n",
    "\n",
    "One of the obvious drawbacks of the KNN algorithm is the **computationally expensive** testing phase which is impractical in industry settings. Furthermore, KNN can suffer from **skewed class** distributions. For example, if a certain class is very frequent in the training set, it will tend to dominate the majority voting of the new example (large number = more common). Finally, the accuracy of KNN can be severely degraded with high-dimension data because there is little difference between the nearest and farthest neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Read the Wine Quality White dataset (``winequality.csv``) from your data folder.\n",
    "\n",
    "Perform the follwong tasks:\n",
    "- select features to be the first 11 columns while the last column to be the target\n",
    "- plot the pair plot for all features\n",
    "- separate the data to 80:20 training and testing datasets\n",
    "- create an instance of Neighbours Classifier and fit the data\n",
    "- Measure the accurary and Root Mean Square Error (RMSE) for the fitted model\n",
    "- Perform grid search to find the best parameters for KNN, for ``weights: ['uniform', 'distance']``, ``n_neighbors: [40, 60, 80, 100, 120, 140]``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('winequality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4995918367346939\n",
      "RMSE: 0.9328472981322575\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'weights': ['uniform', 'distance'], 'n_neighbors': [40, 60, 80, 100, 120, 140]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "0.5687448951810509\n",
      "distance\n",
      "100\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast cancer dataset\n",
      "Accuracy of RBF SVC classifier on training set: 1.00\n",
      "Accuracy of RBF SVC classifier on test set: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "print('Breast cancer dataset')\n",
    "print('Accuracy of RBF SVC classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RBF SVC classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C parameter\n",
    "\n",
    "Try the following codes, express your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast cancer dataset\n",
      "Accuracy of RBF SVC classifier on training set: 0.63\n",
      "Accuracy of RBF SVC classifier on test set: 0.63\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=0.5).fit(X_train, y_train)\n",
    "print('Breast cancer dataset')\n",
    "print('Accuracy of RBF SVC classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of RBF SVC classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "SVM is sensitive to distance/length. Try the following codes and express your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast cancer dataset (normalized with MinMax scaling)\n",
      "RBF-kernel SVC (with MinMax scaling) training set accuracy: 0.98\n",
      "RBF-kernel SVC (with MinMax scaling) test set accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(C=10).fit(X_train_scaled, y_train)\n",
    "print('Breast cancer dataset (normalized with MinMax scaling)')\n",
    "print('RBF-kernel SVC (with MinMax scaling) training set accuracy: {:.2f}'\n",
    "     .format(clf.score(X_train_scaled, y_train)))\n",
    "print('RBF-kernel SVC (with MinMax scaling) test set accuracy: {:.2f}'\n",
    "     .format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
